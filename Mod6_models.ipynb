{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Posting Data Acquisition and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:35:53.707950Z",
     "start_time": "2020-03-26T22:35:50.380423Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "import string\n",
    "\n",
    "from gensim.models import CoherenceModel, ldamulticore\n",
    "from gensim import utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "\n",
    "from dfunc import df_info\n",
    "from dfunc import chi_sq\n",
    "from dfunc import feat_to_dum\n",
    "from dfunc import get_scores\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:35:54.203768Z",
     "start_time": "2020-03-26T22:35:53.710666Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_job_postings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning/Engineering and EDA\n",
    "- Total Observations: 17880 rows\n",
    "- Total Features: 16 columns\n",
    "- Target Variable: 'fraudulent', 0 is real, 1 is false\n",
    "    - 0: 17014\n",
    "    - 1: 866\n",
    "- Features to drop:\n",
    "    - 'title': No standardization of naming job titles, >1000 different titles\n",
    "- Categorical Features: 'location', 'salary_range', 'telecommuting', 'has_company_logo', 'has_questions', 'employment_type', 'required_experience', 'required_education', 'industry', 'function'\n",
    "- NLP Features: 'company_profile', 'description', 'requirements', 'benefits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:35:57.277640Z",
     "start_time": "2020-03-26T22:35:57.274699Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'fraudulent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T22:29:08.453514Z",
     "start_time": "2020-03-25T22:29:08.417566Z"
    }
   },
   "outputs": [],
   "source": [
    "df_info(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:35:58.970740Z",
     "start_time": "2020-03-26T22:35:58.962110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop 'title'\n",
    "df.drop(columns=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrow down to US job postings\n",
    "- 10656 total observations, 730 fake and 9926 real\n",
    "- Minority class: 6.85%, Majority class: 93.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:00.953790Z",
     "start_time": "2020-03-26T22:36:00.939668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only keeping US job postings\n",
    "df = df.loc[df['location'].str[:2] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Chi-squared tests on features with missing values\n",
    "- Null Hypotheses: The proportions of false job reportings for null feature values and non-null feature values are equal\n",
    "- Drop 'function', too many categories, too many missing values, low chi-sq\n",
    "- Drop 'industry, too many categories, too many missing values, low chi-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:51.259247Z",
     "start_time": "2020-03-25T01:46:51.240781Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='department', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:51.843830Z",
     "start_time": "2020-03-25T01:46:51.824767Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='required_education', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:53.931493Z",
     "start_time": "2020-03-25T01:46:53.912243Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='required_experience', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:54.436399Z",
     "start_time": "2020-03-25T01:46:54.417377Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='industry', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:56.956716Z",
     "start_time": "2020-03-25T01:46:56.936338Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='function', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:57.681143Z",
     "start_time": "2020-03-25T01:46:57.657452Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='employment_type', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:58.659551Z",
     "start_time": "2020-03-25T01:46:58.641067Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='salary_range', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:22:50.054624Z",
     "start_time": "2020-03-25T15:22:48.373351Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='company_profile', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:25:53.125797Z",
     "start_time": "2020-03-25T15:25:53.058640Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='requirements', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:26:02.885763Z",
     "start_time": "2020-03-25T15:26:02.846922Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='benefits', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:04.073159Z",
     "start_time": "2020-03-26T22:36:04.066484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df.drop(columns=['industry', 'function', 'requirements', 'benefits'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:53:31.071240Z",
     "start_time": "2020-03-24T00:53:31.047924Z"
    }
   },
   "source": [
    "### Salary range feature\n",
    "- Ratio of fake to real job postings is much greater in postings that include salary range\n",
    "- Convert feature to whether or not salary is posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:06.457238Z",
     "start_time": "2020-03-26T22:36:06.450936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create salary dummy\n",
    "df['salary_range'] = np.where(df['salary_range'].isna() == True, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean location feature\n",
    "- Replace with state dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:08.604021Z",
     "start_time": "2020-03-26T22:36:08.538126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create 'state' feature, if no state exists then 'no state'\n",
    "condition = df['location'].str.extract(r'([A-Z]{2}(?<!US))').notnull()\n",
    "value = df['location'].str.extract(r'([A-Z]{2}(?<!US))')\n",
    "df['state'] = np.where(condition, value, 'No State')\n",
    "df['state'] = np.where((df['state'] == 'AU') | (df['state'] == 'LO'), 'No State', df['state'])\n",
    "df.drop(columns='location', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:08.997256Z",
     "start_time": "2020-03-26T22:36:08.977079Z"
    }
   },
   "outputs": [],
   "source": [
    "df = feat_to_dum(df, 'state', s_value='Unspecified', pref=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Department feature\n",
    "- Convert to dummy, too many different categories with no standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:11.520204Z",
     "start_time": "2020-03-26T22:36:11.514415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert department to dummy\n",
    "df['department'] = np.where(df['department'].isna() == True, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company profile feature\n",
    "- Convert to dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:13.711756Z",
     "start_time": "2020-03-26T22:36:13.705696Z"
    }
   },
   "outputs": [],
   "source": [
    "df['company_profile'] = np.where(df['company_profile'].isna() == True, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining features\n",
    "- Create 'Unspecified' category for Nan values, dummy, the drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:15.810829Z",
     "start_time": "2020-03-26T22:36:15.793158Z"
    }
   },
   "outputs": [],
   "source": [
    "df = feat_to_dum(df, 'employment_type', s_value='Unspecified', pref='et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:16.204220Z",
     "start_time": "2020-03-26T22:36:16.185871Z"
    }
   },
   "outputs": [],
   "source": [
    "df = feat_to_dum(df, 'required_experience', s_value='Unspecified', pref='rex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:16.681112Z",
     "start_time": "2020-03-26T22:36:16.664959Z"
    }
   },
   "outputs": [],
   "source": [
    "df = feat_to_dum(df, 'required_education', s_value='Unspecified', pref='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:22.814727Z",
     "start_time": "2020-03-26T22:36:22.809219Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[target]\n",
    "X = df.drop(columns=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:23.523721Z",
     "start_time": "2020-03-26T22:36:23.513940Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:36:24.884986Z",
     "start_time": "2020-03-26T22:36:24.874557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create splits for text data vs. non-text data\n",
    "X_train_w = X_train[['description']]\n",
    "X_test_w = X_test[['description']]\n",
    "X_train_n = X_train.drop(columns='description')\n",
    "X_test_n = X_test.drop(columns='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:37:48.389543Z",
     "start_time": "2020-03-26T01:37:48.030523Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_1 = PCA(n_components=20)\n",
    "pca_2 = PCA(n_components=40)\n",
    "pca_3 = PCA(n_components=60)\n",
    "\n",
    "principalComponents = pca_1.fit_transform(X_train_n)\n",
    "principalComponents = pca_2.fit_transform(X_train_n)\n",
    "principalComponents = pca_3.fit_transform(X_train_n)\n",
    "\n",
    "print(np.sum(pca_1.explained_variance_ratio_))\n",
    "print(np.sum(pca_2.explained_variance_ratio_))\n",
    "print(np.sum(pca_3.explained_variance_ratio_))\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "principalComponents = pca.fit_transform(X_train_n)\n",
    "print(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:38:16.052408Z",
     "start_time": "2020-03-26T16:38:15.881262Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('pca', PCA(n_components=50)),\n",
    "                    ('clf', LogisticRegression(class_weight='balanced'))])\n",
    "\n",
    "lr_first = pipe_lr.fit(X_train_n, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:38:18.169149Z",
     "start_time": "2020-03-26T16:38:18.141509Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(lr_first, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:34.776412Z",
     "start_time": "2020-03-26T15:07:25.781599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate RandomForest pipeline\n",
    "pipe_rf = Pipeline([('pca', PCA(n_components=50)),\n",
    "                    ('clf', RandomForestClassifier())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_forest = {'clf__n_estimators': [225],\n",
    "                     'clf__criterion': ['gini'],\n",
    "                     'clf__max_depth': [6],\n",
    "                     'clf__class_weight': ['balanced']}\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "                     param_grid=param_grid_forest,\n",
    "                     scoring='f1', cv=5, n_jobs=-1,\n",
    "                     verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_rf.fit(X_train_n, y_train)\n",
    "rf_mod = gs_rf.best_estimator_\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:35.260309Z",
     "start_time": "2020-03-26T15:07:35.108215Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(gs_rf, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:04.756694Z",
     "start_time": "2020-03-26T15:07:49.499567Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost with GridSearchCV params\n",
    "xgb_params = {'clf__n_estimators': [150],\n",
    "              'clf__learning_rate': [0.08],\n",
    "              'clf__max_depth': [8],\n",
    "              'clf__colsample_bytree': [0.7],\n",
    "              'clf__min_child_weight': [1]}\n",
    "\n",
    "# Instantiate XGBoost pipeline\n",
    "pipe_xgb = Pipeline([('pca', PCA(n_components=50)),\n",
    "                     ('clf', xgb.XGBClassifier())])\n",
    "\n",
    "gs_xgb = GridSearchCV(estimator=pipe_xgb,\n",
    "                      param_grid=xgb_params,\n",
    "                      scoring='f1', n_jobs=-1,\n",
    "                      verbose=1, cv=5)\n",
    "\n",
    "gs_xgb.fit(X_train_n, y_train)\n",
    "xgb_mod = gs_xgb.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', gs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:04.856295Z",
     "start_time": "2020-03-26T15:08:04.759464Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(xgb_mod, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:19.270354Z",
     "start_time": "2020-03-26T15:08:15.268536Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_svm = Pipeline([('pca', PCA(n_components=50)),\n",
    "                     ('clf', svm.SVC())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_svm = {'clf__C': [15],\n",
    "                  'clf__kernel': ['rbf'],\n",
    "                  'clf__gamma': [0.3],\n",
    "                  'clf__class_weight': ['balanced']}\n",
    "\n",
    "# Construct grid search\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "                      param_grid=param_grid_svm,\n",
    "                      scoring='f1', cv=5, n_jobs=-1,\n",
    "                      verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_svm.fit(X_train_n, y_train)\n",
    "gs_svm_pipe = gs_svm.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:19.674268Z",
     "start_time": "2020-03-26T15:08:19.272820Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(gs_svm_pipe, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T03:28:08.507214Z",
     "start_time": "2020-03-25T03:28:08.419594Z"
    }
   },
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:14.431117Z",
     "start_time": "2020-03-26T22:36:37.873189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize descriptions\n",
    "data = X_train_w['description'].map(word_tokenize).values\n",
    "data_test = X_test_w['description'].map(word_tokenize).values\n",
    "tokens = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:14.447079Z",
     "start_time": "2020-03-26T22:37:14.434139Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:34.582240Z",
     "start_time": "2020-03-26T22:37:14.451211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create vocabulary data\n",
    "vocab = [ [ word for word in simple_preprocess(str(doc)) if word not in stops ] for doc in tokens ]\n",
    "total_vocabulary = set(word for description in vocab for word in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:36.388535Z",
     "start_time": "2020-03-26T22:37:34.584815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve vocabulary word vectors from GloVe\n",
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:36.399026Z",
     "start_time": "2020-03-26T22:37:36.391213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stolen from learn.co \"Classification With Word Embeddings - Codealong\" lab\n",
    "# transform returns mean word vector from a document\n",
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # Takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:37.531687Z",
     "start_time": "2020-03-26T22:37:36.402824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrames where columns are vector dimensional values from a mean document vector\n",
    "w2v = W2vVectorizer(glove)\n",
    "vec = w2v.transform(data)\n",
    "vec_test = w2v.transform(data_test)\n",
    "vcdf_train = pd.DataFrame(vec)\n",
    "vcdf_test = pd.DataFrame(vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:37.559562Z",
     "start_time": "2020-03-26T22:37:37.534502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join vector columns with previous data\n",
    "X_train_final = X_train_n.reset_index().drop(columns='job_id').join(vcdf_train)\n",
    "X_test_final = X_test_n.reset_index().drop(columns='job_id').join(vcdf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:40.561444Z",
     "start_time": "2020-03-26T22:37:40.558477Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_w2v_mod = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:59.608283Z",
     "start_time": "2020-03-26T22:37:45.271005Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set grid search params\n",
    "param_grid_forest = {'n_estimators': [250],\n",
    "                     'max_depth': [8],\n",
    "                     'class_weight': ['balanced_subsample'],\n",
    "                     'criterion': ['entropy']}\n",
    "\n",
    "# Construct grid search\n",
    "rf_wv = GridSearchCV(estimator=rf_w2v_mod,\n",
    "                     param_grid=param_grid_forest,\n",
    "                     scoring='f1', cv=5, n_jobs=-1,\n",
    "                     verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "rf_wv.fit(X_train_final, y_train)\n",
    "rfwv_final = rf_wv.best_estimator_\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', rf_wv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:37:59.796401Z",
     "start_time": "2020-03-26T22:37:59.611461Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(rfwv_final, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:38:28.391653Z",
     "start_time": "2020-03-26T22:38:03.943237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate RandomForest pipeline\n",
    "pipe_rfwv = Pipeline([('pca', PCA(n_components=90)),\n",
    "                      ('clf', RandomForestClassifier())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_forest = {'clf__n_estimators': [250],\n",
    "                     'clf__criterion': ['entropy'],\n",
    "                     'clf__max_depth': [7],\n",
    "                     'clf__class_weight': ['balanced_subsample']}\n",
    "\n",
    "# Construct grid search\n",
    "gs_rfwv = GridSearchCV(estimator=pipe_rfwv,\n",
    "                       param_grid=param_grid_forest,\n",
    "                       scoring='f1', cv=5, n_jobs=-1,\n",
    "                       verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_rfwv.fit(X_train_final, y_train)\n",
    "pipe_rfwv_mod = gs_rfwv.best_estimator_\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rfwv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:38:28.584936Z",
     "start_time": "2020-03-26T22:38:28.395425Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(pipe_rfwv_mod, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on RandomForest\n",
    "- More false negatives but drastically reduced false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:38:35.809176Z",
     "start_time": "2020-03-26T22:38:35.805395Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_w2v_mod = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:38:49.943485Z",
     "start_time": "2020-03-26T22:38:36.757871Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost with GridSearchCV params\n",
    "xgb_params = {'clf__n_estimators': [150],\n",
    "              'clf__learning_rate': [0.1],\n",
    "              'clf__max_depth': [7],\n",
    "              'clf__colsample_bytree': [0.9],\n",
    "              'clf__min_child_weight': [1]}\n",
    "\n",
    "wv_xgb = GridSearchCV(estimator=xgb_w2v_mod,\n",
    "                      param_grid=xgb_params,\n",
    "                      scoring='f1', n_jobs=-1,\n",
    "                      verbose=1, cv=5)\n",
    "\n",
    "wv_xgb.fit(X_train_final, y_train)\n",
    "xgbwv_mod = wv_xgb.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', wv_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:38:50.001076Z",
     "start_time": "2020-03-26T22:38:49.946126Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(xgbwv_mod, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:39:33.299701Z",
     "start_time": "2020-03-26T22:38:52.866915Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_xgbwv = Pipeline([('pca', PCA(n_components=90)),\n",
    "                       ('clf', xgb.XGBClassifier())])\n",
    "\n",
    "xgb_params = {'clf__n_estimators': [200],\n",
    "              'clf__learning_rate': [0.08],\n",
    "              'clf__max_depth': [8],\n",
    "              'clf__colsample_bytree': [0.7],\n",
    "              'clf__min_child_weight': [0.8]}\n",
    "\n",
    "gswv_xgb = GridSearchCV(estimator=pipe_xgbwv,\n",
    "                        param_grid=xgb_params,\n",
    "                        scoring='f1', n_jobs=-1,\n",
    "                        verbose=1, cv=5)\n",
    "\n",
    "gswv_xgb.fit(X_train_final, y_train)\n",
    "pipe_xgbwv_mod = gswv_xgb.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', gswv_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:39:33.422892Z",
     "start_time": "2020-03-26T22:39:33.302746Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(pipe_xgbwv_mod, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on XGBoost\n",
    "- Improved the model across the board, good precision score (possible the most important metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:45:44.690693Z",
     "start_time": "2020-03-26T16:45:44.424671Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lrwv = Pipeline([('pca', PCA(n_components=90)),\n",
    "                      ('clf', LogisticRegression())])\n",
    "\n",
    "final_lr = pipe_lrwv.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:45:45.448650Z",
     "start_time": "2020-03-26T16:45:45.416970Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(final_lr, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on Logistic Regression\n",
    "- As expected, no substantial improvement (trade-off of recall and precision)\n",
    "- Lack of feature interactions hurts the model, uninterpretable mean word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:34:20.324661Z",
     "start_time": "2020-03-26T15:34:11.032841Z"
    }
   },
   "outputs": [],
   "source": [
    "last_svm = Pipeline([('pca', PCA(n_components=90)),\n",
    "                     ('clf', svm.SVC())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_svm = {'clf__C': [10],\n",
    "                  'clf__kernel': ['rbf'],\n",
    "                  'clf__gamma': [0.3],\n",
    "                  'clf__class_weight': ['balanced']}\n",
    "\n",
    "# Construct grid search\n",
    "wv_svm = GridSearchCV(estimator=last_svm,\n",
    "                      param_grid=param_grid_svm,\n",
    "                      scoring='f1', cv=5, n_jobs=-1,\n",
    "                      verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "wv_svm.fit(X_train_final, y_train)\n",
    "gs_svm_wv = wv_svm.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', wv_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:34:20.952384Z",
     "start_time": "2020-03-26T15:34:20.327804Z"
    }
   },
   "outputs": [],
   "source": [
    "get_scores(gs_svm_wv, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on SVM\n",
    "- Like most other models, drastic reduction in false positives, only slightly more false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T17:06:17.755770Z",
     "start_time": "2020-03-26T17:06:17.750369Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [('Logistic Regression Baseline', lr_first, X_test_n),\n",
    "               ('RandomForest Baseline', rf_mod, X_test_n),\n",
    "               ('SVM Baseline', gs_svm_pipe, X_test_n),\n",
    "               ('XGBoost Baseline', xgb_mod, X_test_n),\n",
    "               ('Logistic Regression Final', final_lr, X_test_final),\n",
    "               ('RandomForest Final', pipe_rfwv_mod, X_test_final),\n",
    "               ('SVM Final', gs_svm_wv, X_test_final),\n",
    "               ('XGBoost Final', xgbwv_mod, X_test_final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T17:13:08.532812Z",
     "start_time": "2020-03-26T17:13:05.334580Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrices of baseline and final models\n",
    "class_names = ['Real', 'Fake']\n",
    "\n",
    "for title, classifier, X_test in classifiers:\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 values_format='.4f',\n",
    "                                 cmap=plt.cm.Reds,\n",
    "                                 normalize='pred')\n",
    "    disp.ax_.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T20:17:39.328989Z",
     "start_time": "2020-03-26T20:17:39.325250Z"
    }
   },
   "source": [
    "## LDA EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T20:56:15.422257Z",
     "start_time": "2020-03-26T20:55:55.998224Z"
    }
   },
   "outputs": [],
   "source": [
    "fake = df.loc[df[target] == 1]['description'].map(word_tokenize).values\n",
    "real = df.loc[df[target] == 0]['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T20:56:37.006330Z",
     "start_time": "2020-03-26T20:56:27.956158Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_fake = [ [ word for word in simple_preprocess(str(doc)) if word not in stops ] for doc in fake ]\n",
    "vocab_real = [ [ word for word in simple_preprocess(str(doc)) if word not in stops ] for doc in real ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
