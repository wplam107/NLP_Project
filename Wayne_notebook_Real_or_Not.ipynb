{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Posting Data Acquisition and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:49.097492Z",
     "start_time": "2020-03-26T15:06:47.207084Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, ldamulticore\n",
    "import string\n",
    "from gensim import utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "\n",
    "from dfunc import df_info\n",
    "from dfunc import chi_sq\n",
    "from dfunc import feat_to_dum\n",
    "from dfunc import get_scores\n",
    "\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:49.661613Z",
     "start_time": "2020-03-26T15:06:49.103316Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_job_postings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning/Engineering and EDA\n",
    "- Total Observations: 17880 rows\n",
    "- Total Features: 16 columns\n",
    "- Target Variable: 'fraudulent', 0 is real, 1 is false\n",
    "    - 0: 17014\n",
    "    - 1: 866\n",
    "- Features to drop:\n",
    "    - 'title': No standardization of naming job titles, >1000 different titles\n",
    "- Categorical Features: 'location', 'salary_range', 'telecommuting', 'has_company_logo', 'has_questions', 'employment_type', 'required_experience', 'required_education', 'industry', 'function'\n",
    "- NLP Features: 'company_profile', 'description', 'requirements', 'benefits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:50.992890Z",
     "start_time": "2020-03-26T15:06:50.989941Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'fraudulent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T22:29:08.453514Z",
     "start_time": "2020-03-25T22:29:08.417566Z"
    }
   },
   "outputs": [],
   "source": [
    "df_info(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:52.759843Z",
     "start_time": "2020-03-26T15:06:52.750679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop 'title'\n",
    "df.drop(columns=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrow down to US job postings\n",
    "- 10656 total observations, 730 fake and 9926 real\n",
    "- Minority class: 6.85%, Majority class: 93.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:54.886660Z",
     "start_time": "2020-03-26T15:06:54.870640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only keeping US job postings\n",
    "df = df.loc[df['location'].str[:2] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Chi-squared tests on features with missing values\n",
    "- Null Hypotheses: The proportions of false job reportings for null feature values and non-null feature values are equal\n",
    "- Drop 'function', too many categories, too many missing values, low chi-sq\n",
    "- Drop 'industry, too many categories, too many missing values, low chi-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:51.259247Z",
     "start_time": "2020-03-25T01:46:51.240781Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='department', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:51.843830Z",
     "start_time": "2020-03-25T01:46:51.824767Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='required_education', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:53.931493Z",
     "start_time": "2020-03-25T01:46:53.912243Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='required_experience', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:54.436399Z",
     "start_time": "2020-03-25T01:46:54.417377Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='industry', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:56.956716Z",
     "start_time": "2020-03-25T01:46:56.936338Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='function', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:57.681143Z",
     "start_time": "2020-03-25T01:46:57.657452Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='employment_type', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T01:46:58.659551Z",
     "start_time": "2020-03-25T01:46:58.641067Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='salary_range', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:22:50.054624Z",
     "start_time": "2020-03-25T15:22:48.373351Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='company_profile', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:25:53.125797Z",
     "start_time": "2020-03-25T15:25:53.058640Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='requirements', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:26:02.885763Z",
     "start_time": "2020-03-25T15:26:02.846922Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_sq(df, feature='benefits', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:56.980759Z",
     "start_time": "2020-03-26T15:06:56.972631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df.drop(columns=['industry', 'function', 'requirements', 'benefits'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:53:31.071240Z",
     "start_time": "2020-03-24T00:53:31.047924Z"
    }
   },
   "source": [
    "### Salary range feature\n",
    "- Ratio of fake to real job postings is much greater in postings that include salary range\n",
    "- Convert feature to whether or not salary is posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:06:58.964992Z",
     "start_time": "2020-03-26T15:06:58.958885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create salary dummy\n",
    "df['salary_range'] = np.where(df['salary_range'].isna() == True, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean location feature\n",
    "- Replace with state dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:01.081595Z",
     "start_time": "2020-03-26T15:07:01.014730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create 'state' feature, if no state exists then 'no state'\n",
    "condition = df['location'].str.extract(r'([A-Z]{2}(?<!US))').notnull()\n",
    "value = df['location'].str.extract(r'([A-Z]{2}(?<!US))')\n",
    "df['state'] = np.where(condition, value, 'No State')\n",
    "df['state'] = np.where((df['state'] == 'AU') | (df['state'] == 'LO'), 'No State', df['state'])\n",
    "df.drop(columns='location', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:01.363426Z",
     "start_time": "2020-03-26T15:07:01.342858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dummied and Dropped: state\n"
     ]
    }
   ],
   "source": [
    "df = feat_to_dum(df, 'state', s_value='Unspecified', pref=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Department feature\n",
    "- Convert to dummy, too many different categories with no standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:03.172205Z",
     "start_time": "2020-03-26T15:07:03.166178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert department to dummy\n",
    "df['department'] = np.where(df['department'].isna() == True, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company profile feature\n",
    "- Convert to dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:04.966855Z",
     "start_time": "2020-03-26T15:07:04.960954Z"
    }
   },
   "outputs": [],
   "source": [
    "df['company_profile'] = np.where(df['company_profile'].isna() == True, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining features\n",
    "- Create 'Unspecified' category for Nan values, dummy, the drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:07.104189Z",
     "start_time": "2020-03-26T15:07:07.086287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dummied and Dropped: employment_type\n"
     ]
    }
   ],
   "source": [
    "df = feat_to_dum(df, 'employment_type', s_value='Unspecified', pref='et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:07.374598Z",
     "start_time": "2020-03-26T15:07:07.351484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dummied and Dropped: required_experience\n"
     ]
    }
   ],
   "source": [
    "df = feat_to_dum(df, 'required_experience', s_value='Unspecified', pref='rex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:07.768253Z",
     "start_time": "2020-03-26T15:07:07.751966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dummied and Dropped: required_education\n"
     ]
    }
   ],
   "source": [
    "df = feat_to_dum(df, 'required_education', s_value='Unspecified', pref='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:10.283773Z",
     "start_time": "2020-03-26T15:07:10.277621Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[target]\n",
    "X = df.drop(columns=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:10.725805Z",
     "start_time": "2020-03-26T15:07:10.715226Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:11.127718Z",
     "start_time": "2020-03-26T15:07:11.118328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create splits for text data vs. non-text data\n",
    "X_train_w = X_train[['description']]\n",
    "X_test_w = X_test[['description']]\n",
    "X_train_n = X_train.drop(columns='description')\n",
    "X_test_n = X_test.drop(columns='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:37:48.389543Z",
     "start_time": "2020-03-26T01:37:48.030523Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_1 = PCA(n_components=20)\n",
    "pca_2 = PCA(n_components=40)\n",
    "pca_3 = PCA(n_components=60)\n",
    "\n",
    "principalComponents = pca_1.fit_transform(X_train_n)\n",
    "principalComponents = pca_2.fit_transform(X_train_n)\n",
    "principalComponents = pca_3.fit_transform(X_train_n)\n",
    "\n",
    "print(np.sum(pca_1.explained_variance_ratio_))\n",
    "print(np.sum(pca_2.explained_variance_ratio_))\n",
    "print(np.sum(pca_3.explained_variance_ratio_))\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "principalComponents = pca.fit_transform(X_train_n)\n",
    "print(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:14.724868Z",
     "start_time": "2020-03-26T15:07:14.549647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=50,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = Pipeline([('pca', PCA(n_components=50)),\n",
    "                    ('clf', LogisticRegression(class_weight='balanced'))])\n",
    "\n",
    "pipe_lr.fit(X_train_n, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:16.043009Z",
     "start_time": "2020-03-26T15:07:16.007762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.3286\n",
      "Accuracy: 0.791\n",
      "Precision: 0.207\n",
      "Recall: 0.7956\n",
      "[[3154  835]\n",
      " [  56  218]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(pipe_lr, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:34.776412Z",
     "start_time": "2020-03-26T15:07:25.781599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.7s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__max_depth': 6, 'clf__n_estimators': 225}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate RandomForest pipeline\n",
    "pipe_rf = Pipeline([('pca', PCA(n_components=50)),\n",
    "                    ('clf', RandomForestClassifier())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_forest = {'clf__n_estimators': [225],\n",
    "                     'clf__criterion': ['gini'],\n",
    "                     'clf__max_depth': [6],\n",
    "                     'clf__class_weight': ['balanced']}\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "                     param_grid=param_grid_forest,\n",
    "                     scoring='f1', cv=5, n_jobs=-1,\n",
    "                     verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_rf.fit(X_train_n, y_train)\n",
    "rf_mod = gs_rf.best_estimator_\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:07:35.260309Z",
     "start_time": "2020-03-26T15:07:35.108215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5421\n",
      "Accuracy: 0.9132\n",
      "Precision: 0.4101\n",
      "Recall: 0.7993\n",
      "[[3674  315]\n",
      " [  55  219]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(gs_rf, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:04.756694Z",
     "start_time": "2020-03-26T15:07:49.499567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.1s remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.08, 'clf__max_depth': 8, 'clf__min_child_weight': 1, 'clf__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with GridSearchCV params\n",
    "xgb_params = {'clf__n_estimators': [150],\n",
    "              'clf__learning_rate': [0.08],\n",
    "              'clf__max_depth': [8],\n",
    "              'clf__colsample_bytree': [0.7],\n",
    "              'clf__min_child_weight': [1]}\n",
    "\n",
    "# Instantiate XGBoost pipeline\n",
    "pipe_xgb = Pipeline([('pca', PCA(n_components=50)),\n",
    "                     ('clf', xgb.XGBClassifier())])\n",
    "\n",
    "gs_xgb = GridSearchCV(estimator=pipe_xgb,\n",
    "                      param_grid=xgb_params,\n",
    "                      scoring='f1', n_jobs=-1,\n",
    "                      verbose=1, cv=5)\n",
    "\n",
    "gs_xgb.fit(X_train_n, y_train)\n",
    "xgb_mod = gs_xgb.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', gs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:04.856295Z",
     "start_time": "2020-03-26T15:08:04.759464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5121\n",
      "Accuracy: 0.9432\n",
      "Precision: 0.5721\n",
      "Recall: 0.4635\n",
      "[[3894   95]\n",
      " [ 147  127]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(xgb_mod, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:19.270354Z",
     "start_time": "2020-03-26T15:08:15.268536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.6s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__C': 15, 'clf__class_weight': 'balanced', 'clf__gamma': 0.3, 'clf__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "pipe_svm = Pipeline([('pca', PCA(n_components=50)),\n",
    "                     ('clf', svm.SVC())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_svm = {'clf__C': [15],\n",
    "                  'clf__kernel': ['rbf'],\n",
    "                  'clf__gamma': [0.3],\n",
    "                  'clf__class_weight': ['balanced']}\n",
    "\n",
    "# Construct grid search\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "                      param_grid=param_grid_svm,\n",
    "                      scoring='f1', cv=5, n_jobs=-1,\n",
    "                      verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_svm.fit(X_train_n, y_train)\n",
    "gs_svm_pipe = gs_svm.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:19.674268Z",
     "start_time": "2020-03-26T15:08:19.272820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5248\n",
      "Accuracy: 0.9167\n",
      "Precision: 0.4144\n",
      "Recall: 0.7153\n",
      "[[3712  277]\n",
      " [  78  196]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(gs_svm_pipe, X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T03:28:08.507214Z",
     "start_time": "2020-03-25T03:28:08.419594Z"
    }
   },
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:09:58.133319Z",
     "start_time": "2020-03-26T15:09:18.916169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize descriptions\n",
    "data = X_train_w['description'].map(word_tokenize).values\n",
    "data_test = X_test_w['description'].map(word_tokenize).values\n",
    "tokens = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:09:58.148661Z",
     "start_time": "2020-03-26T15:09:58.135759Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:07.529100Z",
     "start_time": "2020-03-26T15:09:58.151965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create vocabulary data\n",
    "vocab = [ [ word for word in simple_preprocess(str(doc)) if word not in stops ] for doc in tokens ]\n",
    "total_vocabulary = set(word for description in vocab for word in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:09.458092Z",
     "start_time": "2020-03-26T15:10:07.532186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve vocabulary word vectors from GloVe\n",
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:09.468443Z",
     "start_time": "2020-03-26T15:10:09.460432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stolen from learn.co \"Classification With Word Embeddings - Codealong\" lab\n",
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # Takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:10.835809Z",
     "start_time": "2020-03-26T15:10:09.470961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrames where columns are vector dimensional values from a mean document vector\n",
    "w2v = W2vVectorizer(glove)\n",
    "vec = w2v.transform(data)\n",
    "vec_test = w2v.transform(data_test)\n",
    "vcdf_train = pd.DataFrame(vec)\n",
    "vcdf_test = pd.DataFrame(vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:10.877846Z",
     "start_time": "2020-03-26T15:10:10.838918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join vector columns with previous data\n",
    "X_train_final = X_train_n.reset_index().drop(columns='job_id').join(vcdf_train)\n",
    "X_test_final = X_test_n.reset_index().drop(columns='job_id').join(vcdf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:10.885740Z",
     "start_time": "2020-03-26T15:10:10.882283Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_w2v_mod = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:24.379951Z",
     "start_time": "2020-03-26T15:10:10.888846Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.2s remaining:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# Set grid search params\n",
    "param_grid_forest = {'n_estimators': [250],\n",
    "                     'max_depth': [8],\n",
    "                     'class_weight': ['balanced_subsample'],\n",
    "                     'criterion': ['entropy']}\n",
    "\n",
    "# Construct grid search\n",
    "rf_wv = GridSearchCV(estimator=rf_w2v_mod,\n",
    "                     param_grid=param_grid_forest,\n",
    "                     scoring='f1', cv=5, n_jobs=-1,\n",
    "                     verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "rf_wv.fit(X_train_final, y_train)\n",
    "rfwv_final = rf_wv.best_estimator_\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', rf_wv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:10:24.556170Z",
     "start_time": "2020-03-26T15:10:24.382359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.631\n",
      "Accuracy: 0.9564\n",
      "Precision: 0.6913\n",
      "Recall: 0.5803\n",
      "[[3918   71]\n",
      " [ 115  159]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(rfwv_final, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:12:15.650800Z",
     "start_time": "2020-03-26T15:10:24.558473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__class_weight': 'balanced_subsample', 'clf__criterion': 'entropy', 'clf__max_depth': 7, 'clf__n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate RandomForest pipeline\n",
    "pipe_rfwv = Pipeline([('pca', PCA(n_components=90)),\n",
    "                      ('clf', RandomForestClassifier())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_forest = {'clf__n_estimators': [250],\n",
    "                     'clf__criterion': ['entropy'],\n",
    "                     'clf__max_depth': [7],\n",
    "                     'clf__class_weight': ['balanced_subsample']}\n",
    "\n",
    "# Construct grid search\n",
    "gs_rfwv = GridSearchCV(estimator=pipe_rfwv,\n",
    "                       param_grid=param_grid_forest,\n",
    "                       scoring='f1', cv=5, n_jobs=-1,\n",
    "                       verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_rfwv.fit(X_train_final, y_train)\n",
    "pipe_rfwv_mod = gs_rfwv.best_estimator_\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs_rfwv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:12:15.830207Z",
     "start_time": "2020-03-26T15:12:15.653349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6344\n",
      "Accuracy: 0.9521\n",
      "Precision: 0.6232\n",
      "Recall: 0.646\n",
      "[[3882  107]\n",
      " [  97  177]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(pipe_rfwv_mod, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on RandomForest\n",
    "- More false negatives but drastically reduced false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:13:35.370658Z",
     "start_time": "2020-03-26T15:13:35.367383Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_w2v_mod = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:15:51.891225Z",
     "start_time": "2020-03-26T15:15:23.297187Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   22.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__colsample_bytree': 0.9, 'clf__learning_rate': 0.1, 'clf__max_depth': 7, 'clf__min_child_weight': 1, 'clf__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with GridSearchCV params\n",
    "xgb_params = {'clf__n_estimators': [150],\n",
    "              'clf__learning_rate': [0.1],\n",
    "              'clf__max_depth': [7],\n",
    "              'clf__colsample_bytree': [0.9],\n",
    "              'clf__min_child_weight': [1]}\n",
    "\n",
    "wv_xgb = GridSearchCV(estimator=xgb_w2v_mod,\n",
    "                      param_grid=xgb_params,\n",
    "                      scoring='f1', n_jobs=-1,\n",
    "                      verbose=1, cv=5)\n",
    "\n",
    "wv_xgb.fit(X_train_final, y_train)\n",
    "xgbwv_mod = wv_xgb.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', wv_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:15:51.974401Z",
     "start_time": "2020-03-26T15:15:51.895637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5333\n",
      "Accuracy: 0.9573\n",
      "Precision: 0.8966\n",
      "Recall: 0.3796\n",
      "[[3977   12]\n",
      " [ 170  104]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(xgbwv_mod, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:20:25.235549Z",
     "start_time": "2020-03-26T15:16:38.544381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.08, 'clf__max_depth': 8, 'clf__min_child_weight': 0.8, 'clf__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "pipe_xgbwv = Pipeline([('pca', PCA(n_components=90)),\n",
    "                       ('clf', xgb.XGBClassifier())])\n",
    "\n",
    "xgb_params = {'clf__n_estimators': [200],\n",
    "              'clf__learning_rate': [0.08],\n",
    "              'clf__max_depth': [8],\n",
    "              'clf__colsample_bytree': [0.7],\n",
    "              'clf__min_child_weight': [0.8]}\n",
    "\n",
    "gswv_xgb = GridSearchCV(estimator=pipe_xgbwv,\n",
    "                        param_grid=xgb_params,\n",
    "                        scoring='f1', n_jobs=-1,\n",
    "                        verbose=1, cv=5)\n",
    "\n",
    "gswv_xgb.fit(X_train_final, y_train)\n",
    "pipe_xgbwv_mod = gswv_xgb.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', gswv_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:20:25.359587Z",
     "start_time": "2020-03-26T15:20:25.240070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7018\n",
      "Accuracy: 0.9695\n",
      "Precision: 0.9444\n",
      "Recall: 0.5584\n",
      "[[3980    9]\n",
      " [ 121  153]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(pipe_xgbwv_mod, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on XGBoost\n",
    "- Improved the model across the board, good precision score (possible the most important metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:22:50.029494Z",
     "start_time": "2020-03-26T15:22:49.751105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=90,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lrwv = Pipeline([('pca', PCA(n_components=90)),\n",
    "                      ('clf', LogisticRegression())])\n",
    "\n",
    "pipe_lrwv.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:22:51.604721Z",
     "start_time": "2020-03-26T15:22:51.574575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.3111\n",
      "Accuracy: 0.9418\n",
      "Precision: 0.6512\n",
      "Recall: 0.2044\n",
      "[[3959   30]\n",
      " [ 218   56]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(pipe_lrwv, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on Logistic Regression\n",
    "- As expected, no substantial improvement (trade-off of recall and precision)\n",
    "- Lack of feature interactions hurts the model, uninterpretable mean word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with word vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:34:20.324661Z",
     "start_time": "2020-03-26T15:34:11.032841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:\n",
      " {'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__gamma': 0.3, 'clf__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "last_svm = Pipeline([('pca', PCA(n_components=90)),\n",
    "                     ('clf', svm.SVC())])\n",
    "\n",
    "# Set grid search params\n",
    "param_grid_svm = {'clf__C': [10],\n",
    "                  'clf__kernel': ['rbf'],\n",
    "                  'clf__gamma': [0.3],\n",
    "                  'clf__class_weight': ['balanced']}\n",
    "\n",
    "# Construct grid search\n",
    "wv_svm = GridSearchCV(estimator=last_svm,\n",
    "                      param_grid=param_grid_svm,\n",
    "                      scoring='f1', cv=5, n_jobs=-1,\n",
    "                      verbose=1, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "wv_svm.fit(X_train_final, y_train)\n",
    "gs_svm_wv = wv_svm.best_estimator_\n",
    "\n",
    "print('\\nBest params:\\n', wv_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:34:20.952384Z",
     "start_time": "2020-03-26T15:34:20.327804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7143\n",
      "Accuracy: 0.9653\n",
      "Precision: 0.7582\n",
      "Recall: 0.6752\n",
      "[[3930   59]\n",
      " [  89  185]]\n"
     ]
    }
   ],
   "source": [
    "get_scores(gs_svm_wv, X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words on SVM\n",
    "- Like most other models, drastic reduction in false positives, only slightly more false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:00:49.451360Z",
     "start_time": "2020-03-26T02:00:49.439523Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fake = df.loc[df[target] == 1]['description']\n",
    "real = df.loc[df[target] == 0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:02:00.044895Z",
     "start_time": "2020-03-26T02:01:39.584273Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_tokens = fake.map(word_tokenize).values\n",
    "real_tokens = real.map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:53:41.958162Z",
     "start_time": "2020-03-26T01:53:19.077729Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = df['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:54:08.552737Z",
     "start_time": "2020-03-26T01:54:08.546873Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:54:37.326294Z",
     "start_time": "2020-03-26T01:54:28.885461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create vocabulary from all data\n",
    "vocab = [ [ word for word in simple_preprocess(str(doc)) if word not in stops ] for doc in tokens ]\n",
    "total_vocabulary = set(word for description in vocab for word in description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:54:51.264720Z",
     "start_time": "2020-03-26T01:54:51.260407Z"
    }
   },
   "outputs": [],
   "source": [
    "len(total_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:55:41.381552Z",
     "start_time": "2020-03-26T01:55:39.538147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve vocabulary word vectors from GloVe\n",
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:03:02.832265Z",
     "start_time": "2020-03-26T02:03:01.520241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrames where columns are vector dimensional values from a mean document vector\n",
    "w2v = W2vVectorizer(glove)\n",
    "vector_fake = w2v.transform(fake_tokens)\n",
    "vector_real = w2v.transform(real_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:44:31.481989Z",
     "start_time": "2020-03-26T02:44:03.597199Z"
    }
   },
   "outputs": [],
   "source": [
    "dicty = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        vector = np.array(parts[1:], dtype=np.float32)\n",
    "        if vector in vector_fake:\n",
    "            if word not in dicty.keys():\n",
    "                dicty[word] = 1\n",
    "            else:\n",
    "                dicty[word] += 1\n",
    "dicty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
